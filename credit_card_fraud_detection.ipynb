{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN9fozGh3mqhefuEoueOaBi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdazad173824/PDS-Project/blob/main/credit_card_fraud_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDUYYx93yl-s"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()\n",
        "print(uploaded)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "xMOgwYqE4fNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d nishitsanghvi/credit-card-fraud-detection-logistic-regression"
      ],
      "metadata": {
        "id": "zIVEdqnj_HmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/creditcardfraud.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('data_folder')"
      ],
      "metadata": {
        "id": "sghtAQqD_Sz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "5M-1z1ZnCWAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/data_folder/creditcard.csv\")\n",
        "print(\"Dataset Loaded Successfully!\")\n",
        "data.info()"
      ],
      "metadata": {
        "id": "VWshTuQtC4W6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.head())"
      ],
      "metadata": {
        "id": "yDGGMQgWDTSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get unique values of the 'Class' column\n",
        "unique_classes = data['Class'].unique()\n",
        "\n",
        "print(\"Unique values in the 'Class' column:\", unique_classes)"
      ],
      "metadata": {
        "id": "DprDuOCmDWDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The Amount and Time columns should be scaled because they have different ranges from the other features.\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Scale the 'Amount' and 'Time' columns\n",
        "data['Normalized_Amount'] = StandardScaler().fit_transform(data[['Amount']])\n",
        "data['Normalized_Time'] = StandardScaler().fit_transform(data[['Time']])\n",
        "\n",
        "# Drop the original 'Amount' and 'Time' columns\n",
        "data = data.drop(columns=['Amount', 'Time'])\n",
        "\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "hHJGOcR3DY0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class_counts = data['Class'].value_counts()\n",
        "class_counts.plot(kind='bar', color=['blue', 'red'])\n",
        "\n",
        "class_proportions = data['Class'].value_counts(normalize=True)\n",
        "print(class_proportions)\n",
        "\n",
        "plt.title('Class Distribution')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks([0, 1], ['Non-Fraud', 'Fraud'], rotation=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VADa_zarDkK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target\n",
        "X = data.drop(columns=['Class'])\n",
        "y = data['Class']\n",
        "\n",
        "# Check class distribution\n",
        "print(\"Class distribution before SMOTE:\\n\", y.value_counts())\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "OeqxrpBUDpgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Apply SMOTE to the training data\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Check class distribution after SMOTE\n",
        "print(\"Class distribution after SMOTE:\\n\", pd.Series(y_train_smote).value_counts())"
      ],
      "metadata": {
        "id": "0HWLmm3gDuAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check shape of the new training data\n",
        "print(\"Shape of X_train before SMOTE:\", X_train.shape)\n",
        "print(\"Shape of X_train after SMOTE:\", X_train_smote.shape)\n",
        "\n",
        "# Preview the data\n",
        "print(X_train_smote.head())\n",
        "print(y_train_smote.head())"
      ],
      "metadata": {
        "id": "7hZTi6sFDzK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
        "\n",
        "\n",
        "# Step 6: Train a Logistic Regression model\n",
        "model_lr = LogisticRegression(max_iter=1000, random_state=42)\n",
        "model_lr.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "# Step 7: Evaluate the model on the test set\n",
        "y_pred = model_lr.predict(X_test)\n",
        "\n",
        "# Step 8: Print evaluation metrics\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nROC-AUC Score:\", roc_auc_score(y_test, model_lr.predict_proba(X_test)[:, 1]))\n",
        "\n",
        "# Optional: Display class distributions\n",
        "print(\"\\nClass Distribution Before SMOTE:\")\n",
        "print(y.value_counts())\n",
        "print(\"\\nClass Distribution After SMOTE:\")\n",
        "print(pd.Series(y_train_smote).value_counts())"
      ],
      "metadata": {
        "id": "olh0sWD2D61X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion Matrix Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Fraud', 'Fraud'], yticklabels=['Non-Fraud', 'Fraud'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "otwinq9DEBOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Area Under the Precision-Recall Curve (AUPRC)\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "\n",
        "# Get prediction probabilities for the positive class\n",
        "y_scores = model_lr.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Compute precision and recall\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
        "\n",
        "# Calculate the AUPRC\n",
        "auprc = auc(recall, precision)\n",
        "print(f\"Area Under the Precision-Recall Curve (AUPRC): {auprc:.2f}\")\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the Precision-Recall curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, label=f'Precision-Recall Curve (AUC = {auprc:.2f})', color='blue')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sM-LYOLvEHff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
        "\n",
        "# Calculate probabilities for the test set\n",
        "y_scores = model_lr.predict_proba(X_test)[:, 1]  # Get fraud probabilities\n",
        "\n",
        "# Define a range of thresholds\n",
        "thresholds = np.linspace(0, 1, 20)  # From 0 to 1 in 10 steps\n",
        "\n",
        "# Function to plot confusion matrices\n",
        "def plot_confusion_matrices(thresholds, y_test, y_scores):\n",
        "    fig, axes = plt.subplots(4, 5, figsize=(20, 20))  # Create subplots for 10 thresholds\n",
        "    axes = axes.ravel()  # Flatten the axes for easy iteration\n",
        "\n",
        "    for i, threshold in enumerate(thresholds):\n",
        "        # Generate predictions based on the threshold\n",
        "        y_pred = (y_scores >= threshold).astype(int)\n",
        "\n",
        "        # Compute the confusion matrix\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "        # Plot the confusion matrix\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i])\n",
        "        axes[i].set_title(f\"Threshold: {threshold:.2f}\")\n",
        "        axes[i].set_xlabel(\"Predicted\")\n",
        "        axes[i].set_ylabel(\"Actual\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot confusion matrices for the thresholds\n",
        "plot_confusion_matrices(thresholds, y_test, y_scores)"
      ],
      "metadata": {
        "id": "nlNDQSsOENwm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}